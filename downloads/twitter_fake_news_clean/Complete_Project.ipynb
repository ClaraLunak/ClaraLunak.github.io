{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f8f1fc9-461c-467e-ae95-28598c1de39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# A variable for the columns we want to train our model on\n",
    "columns_to_use = ['user__name', 'tweet__retweet_count', 'user__tweets_per_day', 'tweet__fake', 'user__nr_of_retweets', 'user__friends_count', 'tweet__nr_of_punctuations']\n",
    "\n",
    "# Reads the csv file but only the chosen columns, skips unreadable lines.\n",
    "df = pd.read_csv('data_set_tweet_user_features.csv', usecols=columns_to_use, delimiter=';', on_bad_lines='skip')\n",
    "\n",
    "# Creates a new column showing the users retweet to friends ratio\n",
    "# This is done by dividing nr of retweets with nr friends (+1 to avoid division by 0)\n",
    "df['avg_retweets_per_friend'] = df['user__nr_of_retweets'] / (df['user__friends_count'] + 1)\n",
    "\n",
    "# Drops duplicates and null values\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "\n",
    "# Saves the new csv file locally\n",
    "df.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955d0f1-6c76-423d-9e20-e1e8bb5e0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Reads the data from the processed file\n",
    "df = pd.read_csv('processed_data.csv')\n",
    "\n",
    "# Split into feature matrix X and target vector y (is tweet fake)\n",
    "# We use the numeric features and the username for text vectorization\n",
    "X = df[['user__name', 'tweet__retweet_count', 'user__tweets_per_day', 'avg_retweets_per_friend', 'tweet__nr_of_punctuations']]\n",
    "y = df['tweet__fake']\n",
    "\n",
    "# Divide into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the username text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_text = vectorizer.fit_transform(X_train['user__name'])\n",
    "X_test_text = vectorizer.transform(X_test['user__name'])\n",
    "\n",
    "# Extract the numeric features as arrays\n",
    "X_train_numeric = X_train[['tweet__retweet_count', 'user__tweets_per_day', 'avg_retweets_per_friend', 'tweet__nr_of_punctuations']].values\n",
    "X_test_numeric = X_test[['tweet__retweet_count', 'user__tweets_per_day', 'avg_retweets_per_friend', 'tweet__nr_of_punctuations']].values\n",
    "\n",
    "# Combine the text vectors and numeric features into one sparse matrix\n",
    "X_train_combined = hstack([X_train_text, X_train_numeric])\n",
    "X_test_combined = hstack([X_test_text, X_test_numeric]) \n",
    "\n",
    "# Logistic Regression with hyperparameter tuning\n",
    "lr = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "params_lr = {'C': [1]}\n",
    "grid_lr = GridSearchCV(lr, params_lr, cv=5)\n",
    "grid_lr.fit(X_train_combined, y_train)\n",
    "y_pred_lr = grid_lr.predict(X_test_combined)\n",
    "\n",
    "# Random Forest with hyperparameter tuning\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "params_rf = {'n_estimators': [100], 'max_depth': [None]}\n",
    "grid_rf = GridSearchCV(rf, params_rf, cv=5)\n",
    "grid_rf.fit(X_train_combined, y_train)\n",
    "y_pred_rf = grid_rf.predict(X_test_combined)\n",
    "\n",
    "# Evaluate and print classification reports\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))\n",
    "\n",
    "# Function to plot ROC curves for each model\n",
    "def plot_roc(model, X_test_vec, y_test, label):\n",
    "    y_proba = model.predict_proba(X_test_vec)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure()\n",
    "plot_roc(grid_lr, X_test_combined, y_test, 'Logistic Regression')\n",
    "plot_roc(grid_rf, X_test_combined, y_test, 'Random Forest')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Show distribution of the target classes for us to know the ratio of the data (fake vs real)  \n",
    "print(df['tweet__fake'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec02d6b-6488-4b6a-bf2e-f621b67124c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
